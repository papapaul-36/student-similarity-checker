import streamlit as st
import pandas as pd
from sentence_transformers import SentenceTransformer, util
from collections import Counter
import re

# âœ… ëª¨ë¸ ë¡œë”© (ë“¤ì—¬ì“°ê¸° ì˜¤ë¥˜ ìˆ˜ì •)
@st.cache_resource
def load_model():
    return SentenceTransformer("jhgan/ko-sroberta-multitask")

model = load_model()  # â† ë°˜ë“œì‹œ í•¨ìˆ˜ ë°–ì— ìˆì–´ì•¼ ì •ìƒ ì‘ë™í•¨!

# âœ… Streamlit ì´ˆê¸° ì„¤ì •
st.set_page_config(layout="wide")
st.title("ğŸ“š ìƒê¸°ë¶€ ë¬¸ì¥ ìœ ì‚¬ë„ ê²€ì‚¬ê¸°")

st.markdown("### ğŸ“‚ ì˜ˆì‹œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ")
with open("example.xlsx", "rb") as f:
    st.download_button(
        label="ğŸ“¥ ì—‘ì…€ ì˜ˆì‹œ íŒŒì¼ ë°›ê¸°",
        data=f,
        file_name="ì„¸íŠ¹_ì˜ˆì‹œ.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

uploaded_file = st.file_uploader("ğŸ“ ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ (í•™ìƒ ì´ë¦„, ì„¸íŠ¹ ì „ì²´)", type="xlsx")


# âœ… ê³µí†µ ë‹¨ì–´ í•˜ì´ë¼ì´íŠ¸ í•¨ìˆ˜
def highlight_common_phrases(sentences):
    words_list = [re.findall(r'\b\w+\b', s) for s in sentences]
    flat_words = [word for words in words_list for word in set(words)]
    common_words = [word for word, count in Counter(flat_words).items() if count > 1 and len(word) > 1]
    highlighted = []
    for s in sentences:
        for word in common_words:
            s = re.sub(rf'\b({re.escape(word)})\b', r"<span style='color:red; font-weight:bold;'>\1</span>", s)
        highlighted.append(s)
    return highlighted

# âœ… ì—…ë¡œë“œ í›„ ì²˜ë¦¬
if uploaded_file:
    df = pd.read_excel(uploaded_file)
    expected_cols = {"í•™ìƒ ì´ë¦„", "ì„¸íŠ¹ ì „ì²´"}
    if not expected_cols.issubset(set(df.columns)):
        st.error(f"ì—‘ì…€ì˜ ì—´ ì´ë¦„ì´ ì •í™•í•œì§€ í™•ì¸í•´ì£¼ì„¸ìš”: {expected_cols}")
        st.write("ì—…ë¡œë“œëœ ì—´ ëª©ë¡:", list(df.columns))
        st.stop()

    df["ì„¸íŠ¹ ì „ì²´"] = df["ì„¸íŠ¹ ì „ì²´"].astype(str)

    # ë¬¸ì¥ ë¶„ë¦¬
    sentences, meta = [], []
    for _, row in df.iterrows():
        name = row["í•™ìƒ ì´ë¦„"]
        text = row["ì„¸íŠ¹ ì „ì²´"]
        split_sents = [s.strip() for s in text.replace("\n", " ").split('.') if s.strip()]
        for idx, sent in enumerate(split_sents):
            sentences.append(sent)
            meta.append({"í•™ìƒ": name, "ë¬¸ì¥": sent, "ì „ì²´": text, "ìˆœë²ˆ": idx})

    embeddings = model.encode(sentences, convert_to_tensor=True)
    sim_matrix = util.cos_sim(embeddings, embeddings).cpu().numpy()
    sentence_index_map = {m["ë¬¸ì¥"]: i for i, m in enumerate(meta)}

    # íƒ­ êµ¬ì„±
    tab1, tab2 = st.tabs(["ğŸ‘¤ í•™ìƒë³„ ì„¸íŠ¹ ë³´ê¸°", "ğŸ“‹ ì „ì²´ ìœ ì‚¬ ë¬¸ì¥ ë³´ê¸°"])

    with tab1:
        st.header("ğŸ‘¤ í•™ìƒë³„ ì„¸íŠ¹ ë³´ê¸°")
        student_names = sorted(set(str(m["í•™ìƒ"]) for m in meta if pd.notnull(m["í•™ìƒ"])))
        selected_student = st.selectbox("í•™ìƒ ì„ íƒ", student_names)
        indices = [i for i, m in enumerate(meta) if m["í•™ìƒ"] == selected_student]
        clicked_sentence = None

        st.markdown("### ì„¸íŠ¹ ë‚´ìš©:")
        highlighted = []
        for i in indices:
            m = meta[i]
            s = m["ë¬¸ì¥"]
            scores = sim_matrix[i]
            has_similar = any(scores[j] >= 0.95 and meta[j]["í•™ìƒ"] != selected_student for j in range(len(meta)))
            if has_similar:
                if st.button(f"â­ {s}", key=f"{i}"):
                    clicked_sentence = m["ë¬¸ì¥"]
                highlighted.append(f"<span style='color:red; font-weight:bold;'>{s}</span>")
            else:
                highlighted.append(s)
        st.markdown(" ".join(highlighted), unsafe_allow_html=True)

        if clicked_sentence:
            st.markdown("---")
            st.subheader(f"ğŸ” ìœ ì‚¬ ë¬¸ì¥: '{clicked_sentence}'")
            clicked_idx = sentence_index_map[clicked_sentence]
            sims = sim_matrix[clicked_idx]
            similar_list = []
            for i, score in enumerate(sims):
                if meta[i]["í•™ìƒ"] != selected_student and score >= 0.95:
                    similar_list.append({
                        "í•™ìƒ": meta[i]["í•™ìƒ"],
                        "ë¬¸ì¥": meta[i]["ë¬¸ì¥"],
                        "ìœ ì‚¬ë„": round(float(score), 3)
                    })
            sim_df = pd.DataFrame(similar_list).sort_values(by="ìœ ì‚¬ë„", ascending=False)
            st.dataframe(sim_df, use_container_width=True)

    with tab2:
        st.header("ğŸ‘¥ ìœ ì‚¬ í•™ìƒ ê·¸ë£¹(0.95 ì´ìƒ)")

        # í•™ìƒ ë‹¨ìœ„ ì „ì²´ ì„¸íŠ¹ ìœ ì‚¬ë„
        full_texts = [row["ì„¸íŠ¹ ì „ì²´"] for _, row in df.iterrows()]
        stu_embeddings = model.encode(full_texts, convert_to_tensor=True)
        stu_sim = util.cos_sim(stu_embeddings, stu_embeddings).cpu().numpy()
        stu_names = df["í•™ìƒ ì´ë¦„"].tolist()

        threshold = 0.95
        adj = {name: set() for name in stu_names}
        for i in range(len(stu_names)):
            for j in range(i + 1, len(stu_names)):
                if stu_sim[i][j] >= threshold:
                    adj[stu_names[i]].add(stu_names[j])
                    adj[stu_names[j]].add(stu_names[i])

        from collections import defaultdict, deque

        visited = set()
        groups = []
        for name in stu_names:
            if name not in visited:
                stack = [name]
                comp = []
                while stack:
                    cur = stack.pop()
                    if cur in visited:
                        continue
                    visited.add(cur)
                    comp.append(cur)
                    stack.extend(adj[cur] - visited)
                if len(comp) > 1:
                    groups.append(sorted(comp))

        if not groups:
            st.info("ìœ ì‚¬ í•™ìƒ ê·¸ë£¹(ë‘ ëª… ì´ìƒ)ì´ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

        group_labels = [f"ê·¸ë£¹ {idx+1}: " + ", ".join(g) for idx, g in enumerate(groups)]
        selected_idx = st.selectbox("ğŸ”½ ê·¸ë£¹ ì„ íƒ", range(len(groups)), format_func=lambda i: group_labels[i])
        selected_group = groups[selected_idx]

        st.markdown("---")
        st.subheader("ğŸ“„ ì„ íƒí•œ ê·¸ë£¹ì˜ ìœ ì‚¬ ë¬¸ì¥ ëª¨ìŒ (0.95 ì´ìƒ)")

        sent_graph = defaultdict(set)
        for i in range(len(meta)):
            for j in range(i + 1, len(meta)):
                if meta[i]["í•™ìƒ"] in selected_group and meta[j]["í•™ìƒ"] in selected_group:
                    if sim_matrix[i][j] >= 0.95:
                        sent_graph[i].add(j)
                        sent_graph[j].add(i)

        seen = set()
        components = []
        for i in sent_graph:
            if i not in seen:
                q = deque([i])
                comp = []
                while q:
                    cur = q.popleft()
                    if cur in seen:
                        continue
                    seen.add(cur)
                    comp.append(cur)
                    q.extend(sent_graph[cur] - seen)
                if len(comp) > 1:
                    components.append(comp)

        if not components:
            st.info("0.95 ì´ìƒì˜ ìœ ì‚¬ ë¬¸ì¥ ê·¸ë£¹ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for idx, comp in enumerate(components, 1):
                st.markdown(f"### ğŸ”¹ ë¬¸ì¥ ê·¸ë£¹ {idx}")
                group_sentences = [meta[i]["ë¬¸ì¥"] for i in comp]
                highlighted_sents = highlight_common_phrases(group_sentences)
                for sent, i in zip(highlighted_sents, sorted(comp, key=lambda x: meta[x]["í•™ìƒ"])):
                    student_name = meta[i]["í•™ìƒ"]
                    st.markdown(f"- **{student_name}**: {sent}", unsafe_allow_html=True)
